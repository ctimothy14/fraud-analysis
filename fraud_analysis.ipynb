{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the datasets\n",
    "geo_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\Geo_scores.csv\")\n",
    "scores_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\instance_scores.csv\")\n",
    "lamda_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\Lambda_wts.csv\")\n",
    "qset_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\Qset_tats.csv\")\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\test_share.csv\")\n",
    "train_df = pd.read_csv(\"C:\\\\Users\\\\Tim\\\\OneDrive\\\\Documents\\\\Projects\\\\Fraudulent_financial_trans\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first few rows of each dataset\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lamda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo_scores Row Count: 1424035\n",
      "Geo_scores Column count: 2\n",
      "instance_scores Row Count: 1424035\n",
      "instance_scores Column count: 2\n",
      "Lambda_wts Row Count: 2\n",
      "Lambda_wts Column count: 1400\n",
      "Qset_tats Row Count: 1424035\n",
      "Qset_tats Column count: 2\n",
      "test_share Row Count: 56962\n",
      "test_share Column count: 27\n",
      "train Row Count: 227845\n",
      "train Column count: 28\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows and columns.\n",
    "\n",
    "geo_row_count = len(geo_df)\n",
    "geo_column_count = len(list(geo_df))\n",
    "scores_row_count = len(scores_df)\n",
    "scores_column_count = len(list(scores_df))\n",
    "lamda_row_count = len(list(lamda_df))\n",
    "lambda_column_count = len(lamda_df)\n",
    "qset_row_count = len(qset_df)\n",
    "qset_column_count = len(list(qset_df))\n",
    "test_row_count = len(test_df)\n",
    "test_column_count = len(list(test_df))\n",
    "train_row_count = len(train_df)\n",
    "train_column_count = len(list(train_df))\n",
    "# Can also use print(df.shape) to show total rows & columns.\n",
    "\n",
    "print(\"Geo_scores Row Count: \" + str(geo_row_count))\n",
    "print(\"Geo_scores Column count: \" + str(geo_column_count))\n",
    "\n",
    "print(\"instance_scores Row Count: \" + str(scores_row_count))\n",
    "print(\"instance_scores Column count: \" + str(scores_column_count))\n",
    "\n",
    "print(\"Lambda_wts Row Count: \" + str(lamda_row_count))\n",
    "print(\"Lambda_wts Column count: \" + str(lambda_column_count))\n",
    "\n",
    "print(\"Qset_tats Row Count: \" + str(qset_row_count))\n",
    "print(\"Qset_tats Column count: \" + str(qset_column_count))\n",
    "\n",
    "print(\"test_share Row Count: \" + str(test_row_count))\n",
    "print(\"test_share Column count: \" + str(test_column_count))\n",
    "\n",
    "print(\"train Row Count: \" + str(train_row_count))\n",
    "print(\"train Column count: \" + str(train_column_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify any missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
